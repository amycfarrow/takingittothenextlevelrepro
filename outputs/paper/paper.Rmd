---
title: "The inefficacy of superficial similarities for improving instructor-student relationships"
author: "Amy Farrow"
date: "April 13th, 2021"
header-includes:
  \usepackage{dcolumn}
  \usepackage{rotating}
output:
  bookdown::pdf_document2:
    toc: yes
subtitle: "Replicating ‘Taking It to the Next Level’"
abstract: "This paper replicates the 2019 article 'Taking It to the Next Level' [@citeoriginal], which evaluates an intervention to improve college instructor-student relationship. The modeling results indicate that the intervention, consisting of informing instructors and students about commonalities, has a weak positive effect on student perceptions of instructor-student similarity, but no effect on student perceptions of instructor-student relationship, instructor perception of similarity or instructor-student relationship, grades, or re-enrollment. While the scalability and affordability of the intervention are desirable, there are no results in any of the targeted measures: those that affect and reflect college retention. These results are consistent with the original paper. TODO: revise to clearliy indicate my own findings \\par \\textbf{Keywords:} instructor-student relationship, college, replication study"
thanks: 'Code and data are available at: [github.com/amycfarrow/takingittothenextlevelrepro](https://github.com/amycfarrow/takingittothenextlevelrepro).'
bibliography: references.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(bookdown)    # for cross referencing figures and graphs; referencing
library(kableExtra)  # for nicer tables
library(here) # for working in an RProject
library(Hmisc) # for correlation matrix
library(readstata13) # for stata files
library(finalfit) # for summary table
library(stargazer) # for model table
library(MASS) # for ordinal logistic model
library(cowplot) # for putting plots side by side
library(ltm) # for checking scale validity

# NOTE: script 01_ must have been run already

apply_if <- function(mat, p, f) {
  # Fill NA with FALSE
  p[is.na(p)] <- FALSE
  mat[p] <- f(mat[p])
  mat
}

apaCorr <- function(mat, corrtype = "pearson") {
  matCorr <- mat
  if (class(matCorr) != "rcorr") {
    matCorr <- rcorr(mat, type = corrtype)
  }

  # Add one star for each p < 0.05, 0.01, 0.001
  stars <- apply_if(round(matCorr$r, 2), matCorr$P < 0.05, function(x) paste0(x, "*"))
  stars <- apply_if(stars, matCorr$P < 0.01, function(x) paste0(x, "*"))
  stars <- apply_if(stars, matCorr$P < 0.001, function(x) paste0(x, "*"))
  # Put - on diagonal and blank on upper diagonal
  stars[upper.tri(stars, diag = T)] <- "-"
  stars[upper.tri(stars, diag = F)] <- ""
  n <- length(stars[1,])
  #colnames(stars) <- 1:n
  # Remove _ and convert to title case
  #row.names(stars) <- tools::toTitleCase(sapply(row.names(stars), gsub, pattern="_", replacement = " "))
  # Add index number to row names
  #row.names(stars) <- paste(paste0(1:n,"."), row.names(stars))
  stars
}
```

# Introduction

College is perceived to be a meritocratic tool for social mobility and career success [@college]. Unfortunately, retention is a large problem in contemporary American colleges, and many students begin degrees without completing them; six-year completion rates for full-time first-time students range from 51% to 86%, depending on school [@finishline]. Even when controlling for pre-college test scores and initial enrollments, completion rate disparities exist based on parental education, socio-economic status, and race/ethnicity [@finishline]. Disparities in college completion lead to further entrenchment of long-standing inequalities [@finishline]. Thus, measures to help students persist in college completion are desirable to reduce wasted resources and to increase societal equity.

@citeoriginal's paper, "Taking It to the Next Level: A Field Experiment to Improve Instructor-Student Relationships in College", tests an intervention to improve college retention and performance. In this field experiment, they tested the effect of instructor-student similarity on instructor-student relationships (ISRs) and measures of student success. Based on extensive K-12 research about the importance of instructor-student relationship for student success, @citeoriginal aimed to establish how instructor-student relationships could be improved at the college level, and to test if this improvement had a positive result. The experiment consisted of a randomized controlled trial where some undergraduate students were informed of similarities they shared with their instructor, while others were not. Student and instructor perceptions of similarity and the instructor-student relationship were measured through surveys, and student performance measures were collected from school records.

This paper replicates @citeoriginal's original analysis, using anonymized data provided by the authors. First, methods are discussed, and the measures and scales created by @citeoriginal are evaluated. Second, different demographics of instructor and student populations are explored, similarity of treatment and control groups is established, outcomes of interest are compared for treatment and control groups, and missing data is evaluated. Third, @citeoriginal's models are replicated, and additional models are explored. Linear, logistic, and ordinal logistic models are replicated to predict outcomes including perceived ISR, grade, and persistence. These models show that treatment slightly improves student perception of instructor-student similarity, but does not significantly affect student or instructor ISR perception, grade, exam grade, or future enrollment. Replicating exploratory models, the relationship between similarity and relationship, as well as between relationship and student outcomes, are modeled. Additional models use different controls; specifically, variables indicating shared racial and gender self-identification. As with the replication models, treatment has no significant impact on ISR perception or student outcomes.

## Literature review

TODO: expand this paragraph about interventions, preferably targeting similar ideas to the @citeoriginal paper. What has worked? Draw attention to results. Make sure to refer to any studies that @citeoriginal say are especially influential for their work.

Many interventions to increase completion rates have been suggested and tested. For example, @citecasemanagement studied case managment techniques; @citerecruiting investigated the effect of high school recruitment; @citenearbies identify the importance of interpersonal relationships; @citecertificate argue that certificates awarded prior to degrees can ameliorate the 'college-completion crisis'. These are only a small sample of the interventions suggested. Implementing an effective program is difficult due to complicated causes of attrition, embedded social inequalities, and expenses.

TODO: write a paragraph about research on why similarity builds relationships (similarity -> relationships)

TODO: write a paragraph about research on why relationships matter for scholastic performance (relationships -> grades)
@Abrami_Mizener_1985's study of college students found a . One study of Taiwanese high school students explored the link between shared education and life values and student performance [@Lai_2015]. While they found a significant, but small, positive relationship between life values and student performance on analytic tests, education values gave mixed results depending on the natures of the education value and the analytic test in question [@Lai_2015].

TODO: write a paragraph about research on why relationships matter for persistence (relationships -> persistence)

# Methodology

```{r, warning=FALSE, message=FALSE, echo=FALSE}
isrdata <- read.dta13(here("inputs/data/Instructor-Student Relationships Experiment Data_Anonymous.dta"))
```

```{r, warning=FALSE, message=FALSE, echo=FALSE}
expdata <- isrdata %>%
  filter(t1_consent == 1 # Only include if instructor consented to first survey
         & t1_complete == 1 # Only included if instructor completed first survey
         & t1_timer_consent_3 > 1 # Only include if instructor read consent
         & s1_consent == 1 # Only include if student consented to first survey
         & s1_timer_consent_3 > 1 # Only include if student read consent
         & s1_fullsurvey == 1 # Only include if the student completed the whole first survey
         & t2_complete == 1 # Only include if the instructor completed the whole second survey
         # The rest of the lines make sure that the survey taker looked at each page for more than three seconds
         & t1_timer_gtky1_3 > 10
         & t1_timer_gtky2_3 > 10
         & t1_timer_gtky3_3 > 10
         & t1_timer_demos1_3 > 10
         & t1_timer_demos2_3 > 10
         & s1_timer_gtky1_3 > 10
         & s1_timer_gtky2_3 > 10
         & s1_timer_gtky3_3 > 10
         & s1_timerpre1_3 > 10
         & s1_timerpre2_3 > 10
         & (s1_timercontrolfeedback_3 > 10 | is.na(s1_timercontrolfeedback_3))
         & (s1_timercontrolresponse_3 > 10 | is.na(s1_timercontrolresponse_3))
         & (s1_timertreatmentfeedba_3 > 10 | is.na(s1_timertreatmentfeedba_3))
         & (s1_timertreatmentrespon_3 > 10 | is.na(s1_timertreatmentrespon_3))
         & s1_timerpost1_3 > 10
         & s1_timerpost2_3 > 10
         & s1_timerdemo1_3 > 10
         & (s2_timer1a_3 > 10 | is.na(s2_timer1a_3))
         & (s2_timer1b_3 > 10 | is.na(s2_timer1b_3))
         & (s2_timer2a_3 > 10 | is.na(s2_timer2a_3))
         & (s2_timer3a_3 > 10 | is.na(s2_timer3a_3))
         & (s2_timer3b_3 > 10 | is.na(s2_timer3b_3))
         & (s2_timer3c_3 > 10 | is.na(s2_timer3c_3))
         & (s2_timer4_3 > 10 | is.na(s2_timer4_3))
         & t2_timer > 10
         & t_drop_reasons != "Teacher administered GTKY survey mistakenly at end of semester"
         & t_drop_reasons != "Taught online course"
         & t_drop_reasons != "Administered to only graduate students"
         )

# Alternatively: expdata <- isrdata %>% filter(use == 1) %>% # Select only the cases the original study used.
  
expdata <- expdata %>%
  mutate(across(where(is.numeric), ~na_if(., -99))) %>% # Some NAs are shown as -99. Replace with NA.
  mutate(s_race = as.factor(s_race), # make nominal variables into factors.
         t_race = as.factor(t_race),
         teacherid = as.factor(teacherid),
         f17_enrolled = as.factor(f17_enrolled))
```


```{r, warning=FALSE, message=FALSE, echo=FALSE}
# The original coding of race contained errors -- ex. a professor who selected White and Asian in the survey,
# and was marked as Asian for most cases, but white for one random case.
# This remakes the variable t_race, for consistency
expdata <- expdata %>%
  mutate(t1_race_1 = replace_na(as.numeric(t1_race_1), 0),
         t1_race_2 = replace_na(as.numeric(t1_race_2), 0),
         t1_race_3 = replace_na(as.numeric(t1_race_3), 0),
         t1_race_4 = replace_na(as.numeric(t1_race_4), 0),
         t1_race_5 = replace_na(as.numeric(t1_race_5), 0),
         t1_race_6 = replace_na(as.numeric(t1_race_6), 0),
         t1_race_7 = replace_na(as.numeric(t1_race_7), 0)) %>%
  mutate(t_race = ifelse(t1_race_1 + t1_race_2 + t1_race_3 + t1_race_4 + t1_race_5 + t1_race_6 + t1_race_7 > 1, 
                         ifelse(t1_race_1 == 1, ifelse(t1_race_2 == 1 & t1_race_3 != 1 & t1_race_4 != 1 & t1_race_5 != 1 & t1_race_6 != 1,
                                                       "Black and White",
                                                       ifelse(t1_race_2 != 1 & t1_race_3 == 1 & t1_race_4 != 1 & t1_race_5 != 1 & t1_race_6 != 1,
                                                              "White Hispanic", "Other multi")), 
                                ifelse(t1_race_2 == 1 & t1_race_3 == 1, "Black Hispanic", "Other multi")), 
                         ifelse(t1_race_1 + t1_race_2 + t1_race_3 + t1_race_4 + t1_race_5 + t1_race_6 + t1_race_7 < 1, "Unknown",
                                ifelse(t1_race_1 == 1, "White",
                                       ifelse(t1_race_2 == 1, "Black",
                                              ifelse(t1_race_3 == 1, "Hispanic",
                                                     ifelse(t1_race_4, "Asian",
                                                            ifelse(t1_race_5, "American Indian",
                                                                   ifelse(t1_race_6, "Middle Eastern",
                                                                          "Other")))))))))

expdata <- expdata %>%
  mutate(s1_race_1 = replace_na(as.numeric(s1_race_1), 0),
         s1_race_2 = replace_na(as.numeric(s1_race_2), 0),
         s1_race_3 = replace_na(as.numeric(s1_race_3), 0),
         s1_race_4 = replace_na(as.numeric(s1_race_4), 0),
         s1_race_5 = replace_na(as.numeric(s1_race_5), 0),
         s1_race_6 = replace_na(as.numeric(s1_race_6), 0),
         s1_race_7 = replace_na(as.numeric(s1_race_7), 0)) %>%
  mutate(s_race = ifelse(s1_race_1 + s1_race_2 + s1_race_3 + s1_race_4 + s1_race_5 + s1_race_6 + s1_race_7 > 1,
                         ifelse(s1_race_1 == 1, ifelse(s1_race_2 == 1 & s1_race_3 != 1 & s1_race_4 != 1 & s1_race_5 != 1 & s1_race_6 != 1,
                                                       "Black and White",
                                                       ifelse(s1_race_2 != 1 & s1_race_3 == 1 & s1_race_4 != 1 & s1_race_5 != 1 & s1_race_6 != 1,
                                                              "White Hispanic", "Other multi")), 
                                ifelse(s1_race_2 == 1 & s1_race_3 == 1, "Black Hispanic", "Other multi")), 
                         ifelse(s1_race_1 + s1_race_2 + s1_race_3 + s1_race_4 + s1_race_5 + s1_race_6 + s1_race_7 < 1, "Unknown",
                                ifelse(s1_race_1 == 1, "White",
                                       ifelse(s1_race_2 == 1, "Black",
                                              ifelse(s1_race_3 == 1, "Hispanic",
                                                     ifelse(s1_race_4, "Asian",
                                                            ifelse(s1_race_5, "American Indian",
                                                                   ifelse(s1_race_6, "Middle Eastern",
                                                                          "Other")))))))))
```

@citeoriginal conducted a randomized controlled trial to assess the impact of awareness of instructor-student similarities on perceived similarity, instructor-student relationship, course grade, and re-enrollment.

## Participants

The study took place in the 2017 spring semester at a large Californian University. The study included 120 instructors and their 2,749 students. The instructors participated in the study based on interest and a gift-card incentive, and their students were invited to participate unincentivized. Students were only enrolled in the study for one class, in the event that they were taking classes with multiple participating instructors. The initial sample of 147 instructors was a convenience sample: the study was advertised, interested instructors signed up and were enrolled if their course met the study requirements. 145 instructors consented and took the initial survey, resulting in an corresponding sample of 3,352 students. Once errors of administration, missing responses, and inadequate time spent on surveys were considered, the sample consisted of only 119 instructors and 2,273 students.

## Treatment and control

Participating students were randomly assigned to either treatment or control. At the beginning of the term, all participating students and instructors were given "get to know you" surveys. Using those responses, for each student in the treatment group, seven commonalities were identified between student and instructor (for example, perhaps both student and instructor binge-watch TV to relieve stress, or appreciate loyalty as the most important friend quality), and both student and instructor were informed of these commonalities. They completed a few questions about the similarities and were reminded of them through the semester to ensure they were internalized. Students in the control group were informed about similarities they shared with students in another part of the country, and instructors were told nothing about these students.

## Procedures

All students participated in a survey immediately following the treatment or the placebo. They were surveyed again at the end of the course. Instructors were surveyed only at the end of the course.

## Measures

@citeoriginal identify key measures. Full descriptions of all measures are available in [Appendix A].

Some are extracted from the student survey at the beginning of the term:

  1. Immediately after the treatment or placebo, students answered six questions about their perceived similarity to the instructor, on scales of 1 to 5. These responses were averaged to create a student similarity perception scale.
  2. Immediately after the treatment or placebo, students answered seven questions about their perception of the instructor-student relationship, on scales of 1 to 5. These responses were averaged to create a student ISR perception scale.
  3. Student gender

Others are extracted from the student survey at the end of the term:

  4. At the end of the semester, students answered the student similarity perception scale questions again.
  5. At the end of the semester, students answered seven questions about their perception of the instructor-student relationship, on scales of 1 to 5. These responses were averaged to create a student ISR perception scale.

Others come from the instructor survey at the end of the term:

  6. Instructor similarity perception: At the end of the semester, instructors answered only one question about similarity with the student, on a scale of 1 to 5.
      - Overall, how similar do you think you and STUDENTNAME are?
  7. Instructor ISR perception scale: At the end of the semester, instructors answered seven questions about their perception of the instructor-student relationship, on scales of 1 to 5. These responses were averaged to create an ISR scale.
  8. Final grade: Instructors were asked to report the student's grade on their final exam, paper, or project.

Finally, some are extracted from the university's internal records:

  9. The final grade that the student received in the course.
  10. The student's final grade, standardized against other grades in the course.
  11. The student's cumulative GPA (CGPA) after the Fall 2016 term.
  12. Persistence: The student's status as of Fall term 2017: not enrolled or enrolled.

### Scale Reliability

A scale is externally reliable if it gives the same results across different testings [@Coolican_2014]. Test-retest reliability, where a scale is given to a group at different times, is a common way to assess this [@Coolican_2014]. In our data, there is a retest, but interactions between instructors and students may reasonably be expected to affect the second testing, rendering the data unuseful for assessing test-retest reliability. 

A scale is internally reliable if it is consistent within itself [@Coolican_2014]. Cronbach's alpha was used to assess the reliability of the similarity and ISR scales. This statistic evaluates how much participants vary on individual items, compared to how they vary overall [@Coolican_2014]. Good reliability is indicatedby an alpha between .75 and 1 [@Coolican_2014]. For the initial student similarity scale, initial student ISR scale, end-of-term student similarity scale, end-of-term student ISR scale, and end-of-term student ISR scale, the alpha values were 0.892, 0.872, 0.91, 0.905, and 0.926, respectively, indicating that the scales are reliable.

```{r, warning=FALSE, message=FALSE, echo=FALSE, include=FALSE}
s1_sim_scale <- expdata %>%
  dplyr::select(s1_sim1, s1_sim2, s1_sim3, s1_sim4, s1_sim5, s1_sim6) %>%
  drop_na()
cronbach.alpha(s1_sim_scale)
```

```{r, warning=FALSE, message=FALSE, echo=FALSE, include=FALSE}
s1_tsr_scale <- expdata %>%
  dplyr::select(s1_tsr1, s1_tsr2, s1_tsr3, s1_tsr4, s1_tsr5, s1_tsr6, s1_tsr7) %>%
  drop_na()
cronbach.alpha(s1_tsr_scale)
```

```{r, warning=FALSE, message=FALSE, echo=FALSE, include=FALSE}
s2_sim_scale <- expdata %>%
  dplyr::select(s2_sim1, s2_sim2, s2_sim3, s2_sim4, s2_sim5, s2_sim6) %>%
  drop_na()
cronbach.alpha(s2_sim_scale)
```

```{r, warning=FALSE, message=FALSE, echo=FALSE, include=FALSE}
s2_tsr_scale <- expdata %>%
  dplyr::select(s2_tsr1, s2_tsr2, s2_tsr3, s2_tsr4, s2_tsr5, s2_tsr6, s2_tsr7) %>%
  drop_na()
cronbach.alpha(s2_tsr_scale)
```

```{r, warning=FALSE, message=FALSE, echo=FALSE, include=FALSE}
t2_tsr_scale <- expdata %>%
  dplyr::select(t2_tsr1, t2_tsr2, t2_tsr3, t2_tsr4, t2_tsr5, t2_tsr6, t2_tsr7) %>%
  drop_na()
cronbach.alpha(t2_tsr_scale)
```

### Scale Validity

A scale is valid if it measures what it is supposed to measure [@Coolican_2014]. In this case, the scales should measure perceived similarity and perceived instructor-student relationship (ISR). @citeoriginal used modified versions of the scales from @Gehlbach_Brinkworth_King_Hsu_McIntyre_Rogers_2015, where they were used with ninth-grade American students and their teachers; the scales were originally were presented in @Gehlbach_Brinkworth_Harris_2012, where they were developed for use with sixth-, seventh-, and eight-grade American students and their teachers. Given the fact that these scales were developed for children, it is worth considering what the scales actually measure. To do this, we can look at the specific questions in the three distinct scales.

To assess similarity, students were asked about values, course goals, views on course content, general commonalities, personality, and overall similarity. By this standard, high similarity is when a student shares values, course goals, and views on course content, and the student and instructor have similar personalities, high commonality, and high general similarity. Questions ask about course-specific measures (content and goals), personal traits (values and personality), and non-specific traits (commonalities and general similarity), but do not ask about life experience, abilities, approaches, amoungst other ways that two people can theoretically be similar.

TODO: ^ link to any other definitions/studies of similarity

To assess ISR, students were asked about enjoyment of learning, friendliness, encouragement, excitement, motivation, caring, and overall learning. By this standard, a high-quality ISR is one where a student enjoys learning from, is motivated by, and learns a great deal from a friendly, encouraging, caring instructor, who would be excited to see them in three years time. Questions do not ask about respect, reliability, admiration, challenge, personal growth, frequency of contact, or many other aspects of how a student perceives an instructor-student relationship, especially at the college level.

To assess ISR, instructors were asked about enjoyment of aiding learning, caring, frequency of encouragement, friendliness, excitement, motivation, and overall learning. By this standard, a high-quality ISR is one where an instructor enjoys helping and frequently encourages a friendly, caring student who is motivated and learns a great deal from this instructor, and the instructor would be excited to see the student in three years. Questions do not ask about respectfulness, interest, potential, frequency of contact, tone of that contact, or other aspects of instructor perception of an instructor-student relationship.

TODO: ^^ link to any other definitions of ISR

# Data

TODO: add all citations for R packages, R, and R markdown
The correlation matrix was made using functions by @apacorrcode.

The data, in a .dta format, and Stata code for the @citeoriginal paper are available on the Inter-University Consortium for Political and Social Research [@Robinson_Scott_Gottfried_2020]. The dataset contains 36838 observations of 653 variables.

## Demographics

Table \@ref(tab:demotable1) shows the student covariates for the treatment and control samples. There are no significant differences between the treatment and control groups.

```{r demotable1, echo=FALSE, warning=FALSE, message=FALSE}
# Make a summary table of nominal variables, by treatment group.
demotab <- expdata %>% 
  dplyr::select(treatment, 
                s_female, 
                s_race, 
                s_firstgen,
                s1_age,
                ir_f16_gpa,
                year) %>%
  mutate(year = as.factor(year)) %>%
  mutate(treatment = ff_label(treatment, "Group"),
         s_female = ff_label(s_female, "Student gender"), 
         s1_age = ff_label(s1_age, "Student age"),
         s_race = ff_label(s_race, "Student race"), 
         ir_f16_gpa = ff_label(ir_f16_gpa, "CPGA"),
         s_firstgen = ff_label(s_firstgen, "Student first-gen status"), 
         year = ff_label(year, "Year")) %>%
  summary_factorlist("treatment", 
                     c("s_female", "s_race", "s_firstgen", "year", "s1_age", "ir_f16_gpa"),
                     p = TRUE, 
                     add_dependent_label = TRUE, 
                     dependent_label_prefix = "",
                     add_col_totals = TRUE,
                     add_row_totals = TRUE,
                     include_row_missing_col = TRUE,
                     col_totals_rowname = "",
                     total_col = TRUE,
                     col_totals_prefix = "N(%) = ") %>%
  rename(N = "Total N", Missing = "Missing N") 

# Replace variables that are encoded with their true meanings
demotab[2:3,4] <- c("Male", "Female")
demotab[16:17,4] <- c("No", "Yes")

# Put it all in a nice table.
demotab %>%
  knitr::kable(caption = "Student covariates for treatment and control groups",
               booktabs = TRUE, linesep = "",
               ) %>%
  column_spec(5, width = "5em") %>%
  column_spec(6, width = "5em") %>%
  column_spec(7, width = "5em") %>%
  kableExtra::kable_styling(latex_options = c("scale_down", "striped"),
                            stripe_index =c(2:3, 16:17, 22))


```

Table \@ref(tab:demotable2) shows the instructor covariates. Because instructors are counted multiple times, for each student in the treatment and control groups that is in their course, only the totals are shown. The same covariates, presented by treatment and control groups, are shown in [Appendix B].

```{r demotable2, echo=FALSE, warning=FALSE, message=FALSE}
# make a summary table of continuous variables
demotab2 <- expdata %>% 
  mutate(teacherid = ifelse(as.numeric(teacherid) > 50, "0", "1")) %>%
  dplyr::select(teacherid, t_age, t_firstgen, t_race, t_female, n_course) %>%
  unique() %>%
  mutate(t_age = ff_label(t_age, "Instructor age"), 
         t_female = ff_label(t_female, "Instructor gender"),
         t_race = ff_label(t_race, "Instructor race"),
         t_firstgen = ff_label(t_firstgen, "Instructor first-gen status"),
         n_course = ff_label(n_course, "Course size")) %>%
  summary_factorlist("teacherid",
                     c("t_female", "t_race", "t_firstgen", "t_age", "n_course"),
                     p = TRUE, 
                     add_dependent_label = TRUE, 
                     dependent_label_prefix = "",
                     add_row_totals = TRUE,
                     include_row_missing_col = TRUE,
                     col_totals_rowname = "",
                     total_col = TRUE,
                     add_col_totals = TRUE,
                     col_totals_prefix = "N = ") %>%
  rename(N = "Total N", Missing = "Missing N")

demotab2[2:3,4] <- c("Male", "Female")
demotab2[13:14,4] <- c("No", "Yes")

# put in nice table
demotab2 %>%
  dplyr::select(-"0", -"1", -"p") %>%
  knitr::kable(caption = "Teacher covariates",
               booktabs = TRUE, linesep = "",
               col.names = c("", "N", "Missing", "", "")) %>%
  kableExtra::kable_styling(latex_options = c("striped"), 
                            stripe_index =c(2:3, 13:14, 16))
```

There are differences between the students and instructors. Notably, the student sample is 62.7% female, while the instructor sample is 78.2% female. The student sample is 19.8% White, while the instructor sample is 38.7% White. The student sample is 47% Hispanic, while the instructor sample is only 3.4%. Finally, the student sample is 9.8% multiracial, but the instructor sample is 52.1% multiracial. Some of these differences may be due to self-identification: while one person who is Hispanic may select only Hispanic, another may select, for example, Hispanic as well as White, and be classed differently as a result. For this reason, it is very difficult to draw conclusions. Additionally, students are 43.5% first-generation college students, while only 25.2% of instructors are.

In Figure \@ref(fig:racegraph), we can see that more students identified as Hispanic, while more instructors identified as White and multi-racial.

```{r racegraph, echo=FALSE, warning=FALSE, message=FALSE, fig.width=8, fig.cap="Bar chart illustrating racial identification proprtions of participants"}
instructorrace <- expdata %>%
  dplyr::select(teacherid,
         t1_race_1, t1_race_2, t1_race_3, t1_race_4, t1_race_5, t1_race_6, t1_race_7, t_multi_race) %>%
  unique() %>%
  dplyr::summarize(white = sum(t1_race_1, na.rm = TRUE)/n(),
            black = sum(t1_race_2, na.rm = TRUE)/n(),
            hispanic = sum(t1_race_3, na.rm = TRUE)/n(),
            asian = sum(t1_race_4, na.rm = TRUE)/n(),
            americanindian = sum(t1_race_5, na.rm = TRUE)/n(),
            middleeastern = sum(t1_race_6, na.rm = TRUE)/n(),
            other = sum(t1_race_7, na.rm = TRUE)/n(),
            mixed = sum(t_multi_race > 1, na.rm = TRUE)/n())
studentrace <- expdata %>%
  dplyr::select(id,
         s1_race_1, s1_race_2, s1_race_3, s1_race_4, s1_race_5, s1_race_6, s1_race_7, s_multi_race) %>%
  unique() %>%
  dplyr::summarize(white = sum(s1_race_1, na.rm = TRUE)/n(),
            black = sum(s1_race_2, na.rm = TRUE)/n(),
            hispanic = sum(s1_race_3, na.rm = TRUE)/n(),
            asian = sum(s1_race_4, na.rm = TRUE)/n(),
            americanindian = sum(s1_race_5, na.rm = TRUE)/n(),
            middleeastern = sum(s1_race_6, na.rm = TRUE)/n(),
            other = sum(s1_race_7, na.rm = TRUE)/n(),
            mixed = sum(s_multi_race > 1, na.rm = TRUE)/n())

bind_cols(as_tibble(cbind(nms = names(instructorrace), t(instructorrace))),
          as_tibble(cbind(nms = names(studentrace), t(studentrace))))%>%
  dplyr::select(-nms...3) %>%
  pivot_longer(!nms...1, names_to = "group", values_to = "portion") %>%
  ggplot() +
  geom_col(aes(x = nms...1, y = as.numeric(portion), fill = group), position = "dodge") +
  scale_x_discrete(labels = c("American Indian", "Asian", "Black", "Hispanic", "Middle Eastern", "Multiple", "Other", "White")) +
  scale_fill_discrete(labels = c("Instructors", "Students")) +
  labs(x = "Self-identified race", y = "Proportion of sample", fill = "Group", title = "Self-identified racial proportions different for instructors and students") +
  theme_minimal()
```

In Figure \@ref(fig:classsizegraph), we can see that most class sizes are between 25 and 50 students, but there are some that are much larger.

```{r classsizegraph, echo=FALSE, warning=FALSE, message=FALSE, fig.width=5, fig.height = 3, fig.cap="Histogram illustrating class sizes"}
expdata %>%
  dplyr::select(teacherid, n_course) %>%
  unique() %>%
  ggplot(aes(x = n_course)) +
  geom_histogram(binwidth = 5) +
  labs(x = "Class size", y = "Frequency", title = "Some class sizes are very large") +
  theme_minimal()
```

## Outcomes of interest

Table \@ref(tab:summarytable) shows summary statistics for key variables identified by @citeoriginal, including missing values.

```{r summarytable, echo=FALSE, warning=FALSE, message=FALSE}
# Summarize key outcome variables by treatment group
sumtable <- expdata %>% 
  dplyr::select(treatment, 
                s1_sim,
                s1_tsr,
                s2_sim,
                s2_tsr,
                t2_sim1,
                t2_tsr, grade,
                std_grade,
                t2_finalexam,
                f17_enrolled) %>%
  mutate(t2_sim1 = as.factor(t2_sim1)) %>%
  mutate(treatment = ff_label(treatment, "Group"), 
         s1_sim = ff_label(s1_sim, "Initial student similarity perception scale"), 
         s1_tsr = ff_label(s1_tsr, "Initial student ISR perception scale"), 
         s2_sim = ff_label(s2_sim, "End-of-term student similarity perception scale"), 
         s2_tsr = ff_label(s2_tsr, "End-of-term student ISR perception scale"), 
         t2_sim1 = ff_label(t2_sim1, "End-of-term instructor similarity perception"), 
         t2_tsr = ff_label(t2_tsr, "End-of-term instructor ISR perception scale"), 
         grade = ff_label(grade, "Course grade"), 
         std_grade = ff_label(std_grade, "Standardized course grade"), 
         t2_finalexam = ff_label(t2_finalexam, "Final grade"), 
         f17_enrolled = ff_label(f17_enrolled, "Persistence")) %>%
  summary_factorlist("treatment",
                     c("s1_sim", "s1_tsr", "s2_sim", "s2_tsr", "t2_sim1", "t2_tsr",
                       "grade", "std_grade", "t2_finalexam", "f17_enrolled"),
                     p = FALSE, 
                     add_dependent_label = TRUE, 
                     dependent_label_prefix = "",
                     add_col_totals = TRUE,
                     add_row_totals = TRUE,
                     include_row_missing_col = TRUE,
                     col_totals_rowname = "",
                     total_col = TRUE,
                     col_totals_prefix = "N(%) = ") %>%
  rename(N = "Total N", Missing = "Missing N") 

# Rename variables for readability
sumtable[,1] <- c("", "Similarity", "ISR", " Similarity", " ISR", "Similarity ", "", "", "", "", "ISR ", "Course grade", "Stand. grade", "Final grade", "Peristence", "")
# replace nominal encodings with true values
sumtable[15,4] <- "No"
sumtable[16,4] <- "Yes"

# put in table.
sumtable %>%
  knitr::kable(caption = "Outcomes of interest for treatment and control groups",
               booktabs = TRUE, linesep = "",
               col.names = c("", "N", "Missing", "", "Control", "Treatment", "Total")) %>%
  pack_rows("Initial student perception", 2, 3) %>%
  pack_rows("End-of-term student perception", 4, 5) %>%
  pack_rows("End-of-term instructor perception", 6, 11) %>%
  pack_rows("Student outcomes", 12, 15) %>%
  kableExtra::kable_styling(latex_options = c("scale_down", "striped"),
                            stripe_index =c(2,4,6,8,10,13:14))
```

Figure \@ref(fig:continuousoutcomes) shows key continuous outcome distributions for both treatment and control. The only visible differences are in the initial student similarity perception and end-of-term student similarity perception.

```{r continuousoutcomes, echo=FALSE, warning=FALSE, message=FALSE, fig.width=6, fig.height= 10, fig.cap="Histograms illustrating continous and ordinal key outcomes"}
s1_simplot <- expdata %>% 
  ggplot(aes(x = s1_sim, fill = treatment)) +
  geom_histogram(position = "dodge") +
  labs(x = "Initial student similarity", y = "Frequency", fill = "Group") +
  theme_minimal()

s1_tsrplot <- expdata %>% 
  ggplot(aes(x = s1_tsr, fill = treatment)) +
  geom_histogram(position = "dodge") +
  labs(x = "Initial student ISR", y = "Frequency") +
  theme_minimal()

s2_simplot <- expdata %>% 
  ggplot(aes(x = s2_sim, fill = treatment)) +
  geom_histogram(position = "dodge") +
  labs(x = "End-of-term student similarity", y = "Frequency") +
  theme_minimal()

s2_tsrplot <- expdata %>% 
  ggplot(aes(x = s2_tsr, fill = treatment)) +
  geom_histogram(position = "dodge") +
  labs(x = "End-of-term student ISR", y = "Frequency") +
  theme_minimal()

t2_sim1plot <- expdata %>% 
  ggplot(aes(x = t2_sim1, fill = treatment)) +
  geom_histogram(position = "dodge") +
  labs(x = "End-of-term instructor similarity", y = "Frequency") +
  theme_minimal()

t2_tsrplot <- expdata %>% 
  ggplot(aes(x = t2_tsr, fill = treatment)) +
  geom_histogram(position = "dodge") +
  labs(x = "End-of-term instructor ISR", y = "Frequency") +
  theme_minimal()

gradeplot <- expdata %>% 
  ggplot(aes(x = grade, fill = treatment)) +
  geom_histogram(position = "dodge") +
  labs(x = "Course grade", y = "Frequency") +
  theme_minimal()

std_gradeplot <- expdata %>% 
  ggplot(aes(x = std_grade, fill = treatment)) +
  geom_histogram(position = "dodge") +
  labs(x = "Standardized course grade", y = "Frequency") +
  theme_minimal()

t2_finalexamplot <- expdata %>% 
  ggplot(aes(x = t2_finalexam, fill = treatment)) +
  geom_histogram(position = "dodge") +
  labs(x = "Final grade", y = "Frequency") +
  theme_minimal()

combined <- plot_grid(s1_simplot + theme(legend.position = "none"), s1_tsrplot + theme(legend.position = "none"),
          s2_simplot + theme(legend.position = "none"), s2_tsrplot + theme(legend.position = "none"),
          t2_sim1plot + theme(legend.position = "none"), t2_tsrplot + theme(legend.position = "none"),
          std_gradeplot + theme(legend.position = "none"), t2_finalexamplot + theme(legend.position = "none"),
          ncol = 2)

legend <- get_legend(s1_simplot + 
                       guides(color = guide_legend(nrow = 1)) +
                       theme(legend.position = "bottom"))

title <- ggdraw() + 
  draw_label(
    "Most key outcomes unaffected by treatment",
    x = 0,
    hjust = 0
  ) +
  theme(
    plot.margin = margin(0, 0, 0, 7)
  )

plot_grid(title,
          combined,
          legend,
          ncol = 1,
          rel_heights = c(.1, 2, .1))
```

Replicating @citeoriginal's study, Table \@ref(tab:correlationtable) displays a correlation matrix for the measures that @citeoriginal identified as significant. Some measures, unsurprisingly, are highly correlated: grade and standardized grade, and grade and final exam grade. Others are moderately correlated: student initial perceptions of similarity and instructor-student relationship, student end-of-term perceptions of similarity and instructor-student relationship, and instructor end-of-term perceptions of similarity and instructor-student relationship. These last three pairs could indicate that the similarity perception scales and instructor-student relationship perception scales may not be measuring distinct concepts, or that feelings of similarity and positivity in relationships are strongly associated in the classroom.

```{r correlationtable, echo=FALSE, warning=FALSE, message=FALSE}
# Make the summary stats part of the table
summary <- expdata %>% 
  dplyr::select(treatment, 
                s1_sim, s1_tsr, s2_sim, s2_tsr, t2_sim1, t2_tsr, 
                grade, std_grade, t2_finalexam, ir_f16_gpa, f17_enrolled, 
                s1_female, n_course) %>%
  mutate(treatment = ff_label(treatment, "Group"), 
         s1_sim = ff_label(s1_sim, "Initial student similarity perception scale"), 
         s1_tsr = ff_label(s1_tsr, "Initial student ISR perception scale"), 
         s2_sim = ff_label(s2_sim, "End-of-term student similarity perception scale"), 
         s2_tsr = ff_label(s2_tsr, "End-of-term student ISR perception scale"), 
         t2_sim1 = ff_label(t2_sim1, "End-of-term instructor similarity perception"), 
         t2_tsr = ff_label(t2_tsr, "End-of-term instructor ISR perception scale"), 
         grade = ff_label(grade, "Course grade"), 
         std_grade = ff_label(std_grade, "Standardized course grade"), 
         t2_finalexam = ff_label(t2_finalexam, "Final grade"),
         ir_f16_gpa = ff_label(ir_f16_gpa, "CPGA"),
         f17_enrolled = ff_label(f17_enrolled, "Persistence"),
         ir_f16_gpa = ff_label(ir_f16_gpa, "CPGA"),
         n_course = ff_label(n_course, "Course size")) %>%
  summary_factorlist("treatment", 
                     c("s1_sim", "s1_tsr", "s2_sim", "s2_tsr", "t2_sim1", "t2_tsr", "grade",
                       "std_grade", "t2_finalexam", "ir_f16_gpa", "n_course"),
                     p = FALSE, 
                     add_dependent_label = TRUE, 
                     dependent_label_prefix = "",
                     add_col_totals = FALSE,
                     add_row_totals = TRUE,
                     include_row_missing_col = TRUE,
                     col_totals_rowname = "",
                     total_col = TRUE,
                     col_totals_prefix = "N (%) = ") %>%
  dplyr::select("Total N", "Missing N", "Total")

# Make the correlation matrix part of the table
matrix <- data.frame(apaCorr(as.matrix(expdata %>% 
                  dplyr::select(s1_sim, s1_tsr, s2_sim, s2_tsr, t2_sim1, t2_tsr, grade, std_grade, t2_finalexam, ir_f16_gpa, n_course)))) 

# Combine the summary and correlation tables
table <- summary %>%
  bind_cols(matrix) %>%
  rename("Mean (SD)" = Total, N = "Total N", Missing = "Missing N")

# rename the variables for table readability
rownames(table) <- c("Similarity", "ISR", " Similarity", " ISR", "Similarity ", "ISR ", "Course", "Stand. course", "Final", "CGPA", "Size")

# Put in a table.
table %>%
  kable(caption = "Correlation matrix for continuous and ordinal key variables and outcomes",
        booktabs = TRUE,
        col.names = c("N", "Missing", "Mean (SD)", "Similarity", "ISR", "Similarity","ISR",
                      "Similarity", "ISR", "Course", "Stand. course", "Final", "CGPA", "Size")) %>%
  column_spec(1, width = "8em") %>%
  column_spec(4, width = "4em") %>%
  column_spec(5, width = "4em") %>%
  column_spec(6, width = "4em") %>%
  column_spec(7, width = "4em") %>%
  column_spec(8, width = "4em") %>%
  column_spec(9, width = "4em") %>%
  column_spec(10, width = "4em") %>%
  column_spec(11, width = "4em") %>%
  column_spec(12, width = "4em") %>%
  column_spec(13, width = "2.5em") %>%
  column_spec(14, width = "2.5em") %>%
  pack_rows("Initial student perception", 1, 2) %>%
  pack_rows("End-of-term student perception", 3, 4) %>%
  pack_rows("End-of-term instructor perception", 5, 6) %>%
  pack_rows("Grades", 7, 10) %>%
  pack_rows("Course", 11, 11) %>%
  add_header_above(c(" " = 4, "Initial student" = 2, "End-of-term student" = 2,
                     "End-of-term instructor" = 2, "Grades" = 4, "Course" = 1), 
                   align = "l") %>%
  kable_styling(latex_options = c("scale_down"))
```

## Missing data

There are no significant patterns in missing data. [Appendix C] shows the distributions of key variables relative to missing data in other key variables.

## Attrition

129 eligible instructors completed the first survey, but 6 of those instructors did not complete the second survey. Corresponding to the remaining 123 instructors, 2,801 students completed the first survey (1,392 in the treatment group, 1,409 in the control group), but 682 of those students did not complete the second survey (328 in the treatment group, 354 in the control group). The attrition in the treatment and control groups was comparable (24% in the treatment group, 25% in the control group).

## Data selection

From the 36,838 observations, or potential units of study (corresponding to all undergraduate student records of the university), only 2,273 were used in analysis. Units of study were excluded because the instructor did not participate in the study (33,486); the student did not consent (123); the student did not spend more than a second reading the consent page (1); the initial student survey, initial instructor survey, or end-of-term instructor survey was not complete (428); the instructor mistakenly administered the wrong survey (30); the course was online (20); the course was for graduate students (50); or a participant did not spend more than ten seconds reading and answering a page with five or more questions (427). The ten-second time limit is somewhat arbitrary, and a different choice could lead to different study results.

# Models

## Replication models

$treatment_{i}$ is the indicator that treatment was given.

$X_{1i}$ is a vector of student-level covariates (anticipated student ISR, gender, CGPA). Anticipated ISR is used as a control for end-of-term student ISR perception, while gender and CGPA are used as controls for grade based outcomes. @citeoriginal state this is because females earn higher grades generally.

$X_{2j}$ is a vector of instructor-level covariates (course size, teacher ID).

$\epsilon_{ij}$ is a clustered residual.

$\beta_{0}$, $beta_{1}$, $\Gamma_{1}$, $\Gamma_{2}$, and $a_{k}$ are coefficients on the resulting models.

### Linear models

Equation \@ref(eq:linmodel) is @citeoriginal's linear model, used for continuous outcomes. This include complete scale outcomes: immediate student similarity rating (s1_sim), end of semester student similarity rating (s2_sim), end of semester student ISR rating (s2_tsr), and end of semester instructor ISR rating (t2_tsr). Because these scales are created using 6-7 questions answered on a scale of 1 to 5, they have a total of 25 or 30 possible values, they can be treated as continuous variables and modeled using linear functions. It also includes grade-based outcomes: course grade (grade) and objectively graded exam grade (t2_finalexam), both of which are shown on a 4.0 GPA scale.

\begin{equation}
(\#eq:linmodel)
Outcome_{ij} = \beta_{0} + \beta_{1}treatment_{i} + X_{1i}\Gamma_{1} + X_{2j}\Gamma_{2} + \epsilon_{ij}
\end{equation}

### Ordinal logistic models

Equation \@ref(eq:ordlogmodel) is @citeoriginal's ordinal logistic model, used for the ordinal outcome, which is end of semester instructor similarity rating (t2_sim1).

\begin{equation}
(\#eq:ordlogmodel)
prob(outcome_{ij}) = a_{k} + \beta_{1}treatment_{i} + X_{1i}\Gamma_{1} + X_{2j}\Gamma_{2} + \epsilon_{ij} > k
\end{equation}

### Logistic models

Equation \@ref(eq:logmodel) is @citeoriginal's logistic model, used for the binary outcome, which is enrollment in Fall term 2017 (f17_enrolled).

\begin{equation}
(\#eq:logmodel)
prob(outcome_{ij}) = a_{k} + \beta_{1}treatment_{i} + X_{1i}\Gamma_{1} + X_{2j}\Gamma_{2} + \epsilon_{ij} > k
\end{equation}

## Additional models

When creating additional models, I focused on three key outcomes: end-of-term student similarity perception scale, end-of-term student ISR perception scale, and standardized course grade. I selected these because interventions like @citeoriginal's are aimed at improving student outcomes (like course performance) and perceptions that could improve student outcomes (like student ISR perception), and this particular intervention tries to accomplish these goals by improving perceived similarity.

\begin{equation}
(\#eq:mylinmodel)
Outcome_{ij} = \beta_{0} + \beta_{1}treatment_{i} + X_{1i}\Gamma_{1} + X_{2j}\Gamma_{2} + X_{3jk}\Gamma_{3} + \epsilon_{ij}
\end{equation}

Equation \@ref(eq:mylinmodel) shows the linear model used. $X_{3jk}$ represents student-instructor commonality covariates (matching racial self-ID, matching gender self-ID, age difference).

# Results

## Replication results

```{r, echo=FALSE, warning=FALSE, message=FALSE}
# Make all replication models
studentfirstsimilaritymodel <- lm(data = expdata,
                                  formula = s1_sim ~ treatment + n_course + teacherid,
                                     na.action = na.omit)
studentsecondsimilaritymodel <- lm(data = expdata,
                                   formula = s2_sim ~ treatment + n_course + teacherid,
                                     na.action = na.omit)
studentsecondrelationshipmodel <- lm(data = expdata,
                                     formula = s2_tsr ~ treatment + s1_tsr + n_course + teacherid,
                                     na.action = na.omit)
teachersecondrelationshipmodel <- lm(data = expdata,
                                     formula = t2_tsr ~ treatment + n_course + teacherid,
                                     na.action = na.omit)
grademodel <- lm(data = expdata,
                 formula = grade ~ treatment + s1_female + ir_f16_gpa + n_course + teacherid,
                                     na.action = na.omit)
examgrademodel <- lm(data = expdata %>% filter(obj_exam == 1),
                     formula = t2_finalexam ~ treatment + s1_female + ir_f16_gpa + n_course + teacherid,
                                     na.action = na.omit)
teachersecondsimilarity <- polr(formula = as.factor(t2_sim1) ~ treatment + n_course + teacherid,
                                data = expdata,
                                Hess = TRUE,
                                     na.action = na.omit)
enrollmentfallmodel <- glm(data = expdata,
                           formula = f17_enrolled ~ treatment + s1_female + ir_f16_gpa + n_course + teacherid,
                           family = "binomial",
                                     na.action = na.omit)
```

```{r modeltable, results='asis', echo=FALSE, warning=FALSE, message=FALSE}
# Make table to display model results
stargazer(studentfirstsimilaritymodel,
          studentsecondsimilaritymodel,
          studentsecondrelationshipmodel,
          teachersecondrelationshipmodel,
          grademodel,
          examgrademodel,
          teachersecondsimilarity,
          enrollmentfallmodel,
          title = "Replication model results",
          align = TRUE,
          float.env = "sidewaystable",
          no.space = TRUE,
          omit.stat=c("ser","f"),
          column.sep.width = "-10pt",
          label = "tab:modeltable",
          type = "latex",
          header = FALSE,
          omit = c("teacherid"),
          omit.labels = c("Teacher fixed effect"),
          dep.var.labels = c("Student sim. 1",
                             "Student sim. 2",
                             "Student ISR 2",
                             "Instructor ISR 2",
                             "Course grade",
                             "Final grade",
                             "Instructor sim. 2",
                             "Persistence"),
          covariate.labels = c("Treatment", "Student ISR 1", "Student female", "CGPA", "Course size"))
```

In Table \@ref(tab:modeltable), Model 1 shows a statistically significant relationship between treatment and student initial similarity perception. However, the expected increase is only 0.158 on a scale of 1 to 5. Model 2 shows a statistically significant relationship between treatment and student end-of-semester similarity perception. However, the expected increase is only 0.101 on a scale of 1 to 5.

Model 3 shows no significant relationship between treatment and student end-of-semester ISR perception. However, it does show a significant correlation between anticipated student ISR and student end-of-semester ISR. For every 1 point increase in anticipated ISR on a 1 to 5 scale, the expected increase in end-of-semester ISR is 0.674.

Models 4, 5, 6, 7, and 8 show no significant relationship between treatment and instructor end-of-semester ISR perception, course grade, objectively graded exam grade, instructor perception of similarity at the end of the term, and enrollment in the subsequent semester.

```{r, echo=FALSE, warning=FALSE, message=FALSE}
# Make all replication models
studentsecondrelationshipmodel_ <- lm(data = expdata,
                                     formula = s2_tsr ~ treatment + s2_sim + t2_sim1 + n_course + teacherid,
                                     na.action = na.omit)
teachersecondrelationshipmodel_ <- lm(data = expdata,
                                     formula = t2_tsr ~ treatment + s2_sim + t2_sim1 + n_course + teacherid,
                                     na.action = na.omit)
grademodel_ <- lm(data = expdata,
                 formula = grade ~ treatment + s2_tsr + t2_tsr + s1_female + ir_f16_gpa + teacherid,
                                     na.action = na.omit)
examgrademodel_ <- lm(data = expdata %>% filter(obj_exam == 1),
                     formula = t2_finalexam ~ treatment + s2_tsr + t2_tsr + s1_female + ir_f16_gpa + teacherid,
                                     na.action = na.omit)
enrollmentfallmodel_ <- glm(data = expdata,
                           formula = f17_enrolled ~ treatment + s2_tsr + t2_tsr + s1_female + ir_f16_gpa + teacherid,
                           family = "binomial",
                                     na.action = na.omit)
```

```{r noncausaltable, results='asis', echo=FALSE, warning=FALSE, message=FALSE}
# Make table to display model results
stargazer(studentsecondrelationshipmodel_,
          teachersecondrelationshipmodel_,
          grademodel_,
          examgrademodel_,
          enrollmentfallmodel_,
          title = "Replication model results 2",
          align = TRUE,
          #float.env = "sidewaystable",
          no.space = TRUE,
          omit.stat=c("ser","f"),
          column.sep.width = "-10pt",
          label = "tab:noncausaltable",
          type = "latex",
          header = FALSE,
          omit = c("teacherid"),
          omit.labels = c("Teacher fixed effect"),
          dep.var.labels = c("Student ISR 2",
                             "Instructor ISR 2",
                             "Course grade",
                             "Final grade",
                             "Persistence"),
          covariate.labels = c("Treatment",
                             "Student sim. 2",
                             "Instructor sim. 2",
                             "Course size",
                             "Student ISR 2",
                             "Instructor ISR 2",
                             "Student female",
                             "CGPA"))
```

Table \@ref(tab:noncausaltable) considers the relationship between perceived similarity and perceived ISR and the relationship between perceived ISR and student outcomes. Because only the treatment was randomized, we cannot make causal inferences.

In Models 1 and 2, we can see that student and instructor perceived similarity are both significantly related to student and instructor perceived ISR. Unsurprisingly, student perceived similarity is a better predictor of student perceived ISR, and instructor perceived similarity is a better predictor of instructor perceived ISR. Additionally, course size is negatively related to student ISR perception.

Models 3 and 4 show that student ISR perception and instructor ISR perception are both significantly related to course grade and final grade. Instructor perception is a stronger predictor than student perception.

Model 5 indicates that ISR perception is not significantly related to persistence.

TODO: clustered residuals (low priority)

## Additional results

```{r, echo=FALSE, warning=FALSE, message=FALSE}
expdata <- expdata %>%
  mutate(race_match = ifelse(t1_race_1 == s1_race_1
                             & t1_race_2 == s1_race_2 
                             & t1_race_3 == s1_race_3 
                             & t1_race_4 == s1_race_4 
                             & t1_race_5 == s1_race_5 
                             & t1_race_6 == s1_race_6 
                             & t1_race_7 == s1_race_7,
                             1,
                             0)) %>%
  mutate(gend_match = ifelse(t_female == s_female,
                             1,
                             0)) %>%
  mutate(age_dif = t_age - s1_age)
```

```{r, echo=FALSE, warning=FALSE, message=FALSE}
mystudentsecondsimilaritymodel <- lm(data = expdata,
                                     formula = s2_sim ~ treatment + n_course + race_match + gend_match + age_dif,
                                     na.action = na.omit)
mystudentsecondrelationshipmodel <- lm(data = expdata,
                                     formula = s2_tsr ~ treatment + n_course + race_match + gend_match + age_dif,
                                     na.action = na.omit)
mystdgrademodel <- lm(data = expdata,
                      formula = grade ~ treatment + ir_f16_gpa + n_course + race_match + gend_match + age_dif,
                                     na.action = na.omit)
```

```{r mymodeltable, results='asis', echo=FALSE, warning=FALSE, message=FALSE}
# Make table to display model results
stargazer(mystudentsecondsimilaritymodel,
          mystudentsecondrelationshipmodel,
          mystdgrademodel,
          title = "Additional model results",
          align = TRUE,
          no.space = TRUE,
          omit.stat=c("ser","f"),
          column.sep.width = "-10pt",
          label = "tab:mymodeltable",
          type = "latex",
          header = FALSE,
          dep.var.labels = c("Student sim. 2",
                             "Student ISR 2",
                             "Std. course grade"),
          covariate.labels = c("Treatment",
                               "CGPA", 
                               "Course size",
                               "Matching racial self-ID", "Matching gender self-ID", "Age difference")
          )
```

Table \@ref(tab:mymodeltable) shows the results of models that consider matching student-instructor traits. As with the replication results, there is a statistically significant relationship between treatment and student initial similarity perception. However, the expected increase is only 0.108 on a scale of 1 to 5, which is even lower than in the replication models. There is still no significant relationship between treatment and student end-of-semester ISR perception. Additionally, there is no significant relationship between treatment and standardized course grade.

TODO: Shiny.

# Discussion

TODO: why did @citeoriginal pick their models? What do I think about the selection?

TODO: does this study have external validity?

TODO: Inefficacy of weak measures in the face of divergent student/instructor demographics and massive class sizes.

TODO: Who perceives similarity

TODO: What does it mean for relationships and therefore academic success to be built on similarity.

\newpage

# (APPENDIX) Appendix {-} 

# Appendix A

Complete list of key measures

* Initial student survey:
  1. Student similarity perception scale (s1_sim)
      - Overall, how similar to your instructor's values do you think your values are?
      - How similar are your goals for the course and your instructor's goals?
      - In general, how similar do you think your views about the course content and your instructor's are?
      - How much do you think you have in common with your instructor?
      - How similar do you think your personality is compared to your instructor's?
      - Overall, how similar do you think you and your instructor are?
  2. Student ISR perception scale (s1_tsr)
      - How much do you think you will enjoy learning from this instructor?
      - How friendly do you think this instructor will be towards you?
      - How encouraging do you think this instructor will be towards you?
      - If you came back to visit this instructor three years from now, how excited do you think they would be?
      - How motivating do you think you will find this instructor's class?
      - How caring do you think this instructor will be towards you?
      - Overall, how much do you think you will learn from this instructor?
  3. Student gender (s1_female)
* End of term student survey:
  4. Student similarity perception scale (s2_sim)
  5. Student ISR perception scale (s2_tsr)
      - How much do you enjoy learning from this professor?
      - How friendly do you think this professor is towards you?
      - If you came back to visit this professor three years from now, how excited do you think they would be?
      - How motivating do you find this professor's class?
      - How caring do you think this professor is towards you?
      - How encouraging do you think this professor is towards you?
      - Overall, how much do you think you have learned from this professor?
* End of term instructor survey:
  6. Instructor similarity perception (t2_sim1):
      - Overall, how similar do you think you and STUDENTNAME are?
  7. Instructor ISR perception scale (t2_tsr):
      - How much did you enjoy helping STUDENTNAME learn?
      - How caring was STUDENTNAME towards you?
      - How often did you say something encouraging to STUDENTNAME?
      - How friendly was STUDENTNAME towards you?
      - If this student came back to visit you three years from now, how excited would you be?
      - How motivating did STUDENTNAME find the activities that you plan for class?
      - Overall, how much did STUDENTNAME learn from you?
  8. Final grade (t2_finalexam): Instructors were asked to report the student's grade on their final exam, paper, or project.
* University internal records:
  9. Course grade (grade): The final grade that the student received in the course.
  10. Standardized course grade (std_grade): The student's final grade, standardized against other grades in the course.
  11. CGPA (ir_f16_gpa): The student's cumulative GPA after the Fall 2016 term.
  12. Persistence (f17_enrolled): The student's status as of Fall term 2017: not enrolled or enrolled.
  
# Appendix B

```{r demotable3, echo=FALSE, warning=FALSE, message=FALSE}
# Make a summary table of nominal variables, by treatment group.
demotab3 <- expdata %>% 
  dplyr::select(treatment, 
                t_female, 
                t_race, 
                t_firstgen,
                t_age,
                n_course) %>%
  mutate(treatment = ff_label(treatment, "Group"),
         t_female = ff_label(t_female, "Teacher gender"), 
         t_age = ff_label(t_age, "Teacher age"),
         t_race = ff_label(t_race, "Teacher race"), 
         t_firstgen = ff_label(t_firstgen, "Teacher first-gen status"), 
         n_course = ff_label(n_course, "Course size")) %>%
  summary_factorlist("treatment", 
                     c("t_female", "t_race", "t_firstgen", "t_age", "n_course"),
                     p = TRUE, 
                     add_dependent_label = TRUE, 
                     dependent_label_prefix = "",
                     add_col_totals = TRUE,
                     add_row_totals = TRUE,
                     include_row_missing_col = TRUE,
                     col_totals_rowname = "",
                     total_col = TRUE,
                     col_totals_prefix = "N(%) = ") %>%
  rename(N = "Total N", Missing = "Missing N") 

# Replace variables that are encoded with their true meanings
demotab3[2:3,4] <- c("Male", "Female")
demotab3[13:14,4] <- c("No", "Yes")

# Put it all in a nice table.
demotab3 %>%
  knitr::kable(caption = "Teacher covariates for treatment and control groups",
               booktabs = TRUE, linesep = "",
               ) %>%
  column_spec(5, width = "5em") %>%
  column_spec(6, width = "5em") %>%
  column_spec(7, width = "5em") %>%
  kableExtra::kable_styling(latex_options = c("scale_down", "striped", "hold_position"),
                            stripe_index =c(2:3, 13:14, 16))


```

# Appendix C

```{r missingdata, echo=FALSE, warning=FALSE, message=FALSE, fig.height=9, fig.width=9}
explanatory = c("s2_tsr", "s1_tsr", "ir_f16_gpa", "n_course", "s1_female")
dependent = "treatment"

expdata %>%
  dplyr::select(treatment, 
                s1_sim, s1_tsr, s2_sim, s2_tsr, t2_sim1, t2_tsr, 
                grade, std_grade, t2_finalexam, ir_f16_gpa, f17_enrolled, 
                s1_female, n_course) %>%
  missing_pairs(dependent, explanatory)
```

\newpage

# References
